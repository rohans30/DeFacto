{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import autogen\n",
    "from autogen import ConversableAgent\n",
    "import os\n",
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# pdf_text = extract_text_from_pdf(\"mock_trial.pdf\")\n",
    "pdf_text = extract_text_from_pdf(\"./Mini-Mock-Trial-State-v.-Anderson-2016.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text):\n",
    "    return len(text) // 4\n",
    "\n",
    "total_tokens = estimate_tokens(pdf_text)\n",
    "print(f\"Estimated tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key NOT found. Double-check your environment variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if API key is loaded\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully.\")\n",
    "else:\n",
    "    print(\"API key NOT found. Double-check your environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_config = {\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": openai_api_key}]}\n",
    "llm_config = {\"config_list\": [{\"model\": \"llama3.2:latest\", \"api_type\": \"ollama\", \"client_host\": \"http://127.0.0.1:11434\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user to select a role\n",
    "user_role = input(\"Would you like to role-play as the Defense Attorney or Prosecuting Attorney? Type DA or PA to confirm your selection.\").strip().upper()\n",
    "\n",
    "# Ensure valid selection\n",
    "while user_role not in [\"DA\", \"PA\"]:\n",
    "    user_role = input(\"Invalid role. Please enter DA or PA. \\n\\n Would you like to role-play as the Defense Attorney or Prosecuting Attorney? Type DA or PA to confirm your selection.\").strip().upper()\n",
    "\n",
    "agents = {}\n",
    "human_proxy_role = \"\"\n",
    "\n",
    "prosecuting_attorney_prompt = \"\"\"\n",
    "You are the Prosecuting Attorney (Deputy DA) in this mock trial. Your role is to present evidence and argue the case on behalf of the prosecution. Follow courtroom procedure, make legal arguments, and question witnesses to prove the defendant's guilt.\n",
    "Do not simulate conversations with attorneys, the judge, or other witnesses. Focus on your role as the Prosecuting Attorney.\n",
    "\"\"\"\n",
    "\n",
    "defense_attorney_prompt = \"\"\"\n",
    "You are the Defense Attorney in this mock trial. Your role is to defend the defendant by creating reasonable doubt and presenting legal arguments that support their innocence. Cross-examine witnesses and challenge the prosecution's claims.\n",
    "Do not simulate conversations with attorneys, the judge, or other witnesses. Focus on your role as the Defense Attorney.\n",
    "\"\"\"\n",
    "\n",
    "if user_role == \"DA\":\n",
    "    human_proxy_role = \"defense attorney\"\n",
    "\n",
    "    agents[\"prosecuting_attorney\"] = ConversableAgent(\n",
    "        \"prosecuting_attorney\",\n",
    "        system_message=prosecuting_attorney_prompt,\n",
    "        llm_config=llm_config,\n",
    "        description=\"\"\"\n",
    "        Acts as the Prosecuting Attorney in a mock trial. \n",
    "        Responsible for representing the state or prosecution, presenting evidence, making legal arguments, and proving the defendant's guilt beyond a reasonable doubt.\n",
    "        Tasks include delivering opening and closing statements, questioning witnesses, introducing exhibits, and arguing relevant points of law.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    agents[\"human_proxy\"] = ConversableAgent(\n",
    "        \"human_proxy-defense_attorney\",\n",
    "        llm_config=False,\n",
    "        human_input_mode=\"ALWAYS\",\n",
    "        description=\"\"\"\n",
    "        Acts as the Defense Attorney in a mock trial. \n",
    "        Responsible for representing the defendant by crafting a defense strategy, challenging the prosecution's case, cross-examining witnesses, and presenting evidence that supports the defendant's innocence or mitigates their liability.\n",
    "        \"\"\"\n",
    "    )\n",
    "else:\n",
    "    human_proxy_role = \"defense attorney\"\n",
    "    \n",
    "    agents[\"defense_attorney\"] = ConversableAgent(\n",
    "        \"defense_attorney\",\n",
    "        system_message=defense_attorney_prompt,\n",
    "        llm_config=llm_config,\n",
    "        description=\"\"\"\n",
    "        Acts as the Defense Attorney in a mock trial. \n",
    "        Responsible for representing the defendant, delivering legal arguments, challenging the prosecution's claims, and advocating for the most favorable outcome for their client through legal defense strategies and courtroom procedure.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    agents[\"human_proxy\"] = ConversableAgent(\n",
    "        \"human_proxy-prosecuting_attorney\",\n",
    "        llm_config=False,\n",
    "        human_input_mode=\"ALWAYS\",\n",
    "        description=\"\"\"\n",
    "        Acts as the Prosecuting Attorney in a mock trial. \n",
    "        Responsible for presenting the case against the defendant, introducing evidence, questioning witnesses, and making legal arguments that establish the defendant's guilt under the applicable law.\n",
    "        The Prosecuting Attorney seeks to achieve a conviction through clear and compelling arguments based on the trial's evidence.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents[\"judge_agent\"] = ConversableAgent(\n",
    "    \"judge_agent\", \n",
    "    system_message=\"\"\"\n",
    "    You are a judge presiding over a mock trial. \n",
    "    Answer all questions **only from the judge's perspective**, making legal rulings, managing courtroom procedures, and ensuring a fair trial. \n",
    "    Do not simulate conversations between other trial participants or generate responses for other roles. Focus solely on delivering rulings and courtroom instructions.\n",
    "    \"\"\", \n",
    "    llm_config=llm_config,  \n",
    "    description=\"\"\"\n",
    "    Presides over the mock trial as the judge. \n",
    "    Responsible for ensuring the trial proceeds fairly and in accordance with legal principles. \n",
    "    Duties include interpreting the law, making procedural rulings, managing courtroom conduct, \n",
    "    overseeing the admissibility of evidence, ruling on objections, and instructing the jury. \n",
    "    The judge must remain impartial while facilitating the smooth progression of the trial.\n",
    "    \"\"\",\n",
    "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\"),\n",
    ")\n",
    "\n",
    "agents[\"defendant_agent\"] = ConversableAgent(\n",
    "    name=\"defendant_agent\", \n",
    "    system_message=\"\"\"\n",
    "    You are the defendant in a mock trial. \n",
    "    Answer all questions **only from the defendant's perspective**, responding truthfully and according to the trial document. \n",
    "    Do not simulate conversations with attorneys, the judge, or other witnesses. Wait until you are directly questioned or called to testify.\n",
    "    \"\"\", \n",
    "    llm_config=llm_config, \n",
    "    description=\"\"\"\n",
    "    Represents the defendant in the mock trial. \n",
    "    Provides testimony when called to the stand, responds to direct and cross-examination questions, \n",
    "    and defends against accusations by presenting their version of events as established in the trial document. \n",
    "    The defendant must remain truthful and consistent with the provided case facts while adhering to courtroom protocol.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "agents[\"witness_agent\"] = ConversableAgent(\n",
    "    name=\"witness_agent\", \n",
    "    system_message=\"\"\"\n",
    "    You are a witness in a mock trial. \n",
    "    Only respond **when a specific witness is referenced or called**. \n",
    "    Answer questions **only from the relevant witnessâ€™s perspective** based on the trial document. \n",
    "    Do not simulate conversations between the witness and other trial participants. Avoid generating content for other roles.\n",
    "    \"\"\", \n",
    "    llm_config=llm_config, \n",
    "    description=\"\"\"\n",
    "    Represents all potential witnesses in the mock trial. \n",
    "    Responds only when directly referenced, adhering strictly to the details and character profiles described in the trial document.\n",
    "    Follows legal procedures during direct and cross-examinations, providing truthful and consistent testimony in accordance with courtroom protocol.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_proxy = ConversableAgent(\n",
    "#     \"human_proxy\",\n",
    "#     llm_config=False,  # no LLM used for human proxy\n",
    "#     human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    "#     description=\"Represents the human user roleplaying as the Deputy DA, directing the flow of the trial and interacting with other agents.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat = GroupChat(\n",
    "    agents=agents.values(),\n",
    "    messages=[],\n",
    "    max_round=2,\n",
    "    allow_repeat_speaker=False,\n",
    ")\n",
    "\n",
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config=llm_config, \n",
    "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = f\"\"\"\n",
    "I will be roleplaying as the {human_proxy_role} in this mock trial. I want to start from the direct examination where the defendant is already at the stand and I as the {human_proxy_role} am questioning them.\n",
    "\n",
    "Here is the full trial document:\n",
    "\n",
    "{pdf_text}\n",
    "Is everyone ready?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial conversation\n",
    "chat_result = agents[\"human_proxy\"].initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=initial_message,\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # prev_chat = group_chat_manager.messages_from_string(chat_result.chat_history)\n",
    "    prev_chat = chat_result.chat_history\n",
    "    last_agent, last_message = group_chat_manager.resume(messages = prev_chat, remove_termination_string=\"TERMINATE\")\n",
    "\n",
    "    next_user_input = input(\"EXAMPLE OF ASKING HUMAN INPUT TO STOP CHATS: How would you like to reply?\")\n",
    "\n",
    "    # next_message = f\"\"\"\n",
    "    # I have been roleplaying as the {human_proxy_role} in this mock trial. My next question is {next_user_input}\n",
    "    # \"\"\"\n",
    "\n",
    "    chat_result = agents[\"human_proxy\"].initiate_chat(\n",
    "        group_chat_manager,\n",
    "        message = next_user_input,\n",
    "        clear_history = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini\",  # Choose model with sufficient token capacity\n",
    "#     messages=[{\"role\": \"system\", \"content\": roleplay_prompt}]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defacto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
